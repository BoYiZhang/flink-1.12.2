/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package org.apache.flink.client;

import org.apache.flink.api.dag.Pipeline;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.runtime.jobgraph.JobGraph;

/**
 * Utility for transforming {@link Pipeline FlinkPipelines} into a {@link JobGraph}. This uses
 * reflection or service discovery to find the right {@link FlinkPipelineTranslator} for a given
 * subclass of {@link Pipeline}.
 */
public final class FlinkPipelineTranslationUtil {

    /** Transmogrifies the given {@link Pipeline} to a {@link JobGraph}. */
    public static JobGraph getJobGraph(
            Pipeline pipeline, Configuration optimizerConfiguration, int defaultParallelism) {

        // pipeline :

        //    pipeline = {StreamGraph@3473}
        //        jobName = "Socket Window WordCount"
        //        executionConfig = {ExecutionConfig@3482} "ExecutionConfig{executionMode=PIPELINED, closureCleanerLevel=RECURSIVE, parallelism=4, maxParallelism=-1, numberOfExecutionRetries=-1, forceKryo=false, disableGenericTypes=false, enableAutoGeneratedUids=true, objectReuse=false, autoTypeRegistrationEnabled=true, forceAvro=false, autoWatermarkInterval=200, latencyTrackingInterval=0, isLatencyTrackingConfigured=false, executionRetryDelay=10000, restartStrategyConfiguration=Cluster level default restart strategy, taskCancellationIntervalMillis=-1, taskCancellationTimeoutMillis=-1, useSnapshotCompression=false, defaultInputDependencyConstraint=ANY, globalJobParameters=org.apache.flink.api.common.ExecutionConfig$GlobalJobParameters@1, registeredTypesWithKryoSerializers={}, registeredTypesWithKryoSerializerClasses={}, defaultKryoSerializers={}, defaultKryoSerializerClasses={}, registeredKryoTypes=[], registeredPojoTypes=[]}"
        //        checkpointConfig = {CheckpointConfig@3483}
        //        savepointRestoreSettings = {SavepointRestoreSettings@3484} "SavepointRestoreSettings.none()"
        //        scheduleMode = {ScheduleMode@3485} "EAGER"
        //        chaining = true
        //        userArtifacts = {ArrayList@3486}  size = 0
        //        timeCharacteristic = {TimeCharacteristic@3487} "EventTime"
        //        globalDataExchangeMode = {GlobalDataExchangeMode@3488} "ALL_EDGES_PIPELINED"
        //        allVerticesInSameSlotSharingGroupByDefault = true
        //        streamNodes = {HashMap@3489}  size = 4
        //                {Integer@3582} 1 -> {StreamNode@3604} "Source: Socket Stream-1"
        //                {Integer@3605} 2 -> {StreamNode@3606} "Flat Map-2"
        //                {Integer@3569} 4 -> {StreamNode@3607} "Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, ReduceFunction$1, PassThroughWindowFunction)-4"
        //                {Integer@3580} 5 -> {StreamNode@3608} "Sink: Print to Std. Out-5"
        //        sources = {HashSet@3490}  size = 1
        //        0 = {Integer@3582} 1
        //        sinks = {HashSet@3491}  size = 1
        //        0 = {Integer@3580} 5
        //        virtualSideOutputNodes = {HashMap@3492}  size = 0
        //        virtualPartitionNodes = {HashMap@3493}  size = 1
        //                {Integer@3616} 6 -> {Tuple3@3617} "(2,HASH,UNDEFINED)"
        //        vertexIDtoBrokerID = {HashMap@3494}  size = 0
        //        vertexIDtoLoopTimeout = {HashMap@3495}  size = 0
        //        stateBackend = null
        //        iterationSourceSinkPairs = {HashSet@3496}  size = 0
        //        timerServiceProvider = null

        // defaultParallelism : 4

        // optimizerConfiguration :
        //    optimizerConfiguration = {Configuration@3474} "{env.java.opts.client=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5666, taskmanager.memory.process.size=1728m, jobmanager.execution.failover-strategy=region, jobmanager.rpc.address=localhost, execution.target=yarn-per-job, jobmanager.memory.process.size=1600m, security.kerberos.login.use-ticket-cache=true, jobmanager.rpc.port=6123, security.kerberos.login.principal=yarn/henghe-030@HENGHE.COM, sun.security.krb5.debug=true, execution.savepoint.ignore-unclaimed-state=false, execution.attached=true, execution.shutdown-on-attached-exit=false, pipeline.jars=[file:/opt/tools/flink-1.12.0/examples/streaming/SocketWindowWordCount.jar], parallelism.default=4, taskmanager.numberOfTaskSlots=1, pipeline.classpaths=[], security.kerberos.login.keytab=/opt/keytab/yarn.keytab, $internal.deployment.config-dir=/opt/tools/flink-1.12.0/conf}"
        //        confData = {HashMap@3519}  size = 19
        //        "env.java.opts.client" -> "-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5666"
        //        "taskmanager.memory.process.size" -> "1728m"
        //        "jobmanager.execution.failover-strategy" -> "region"
        //        "jobmanager.rpc.address" -> "localhost"
        //        "execution.target" -> "yarn-per-job"
        //        "jobmanager.memory.process.size" -> "1600m"
        //        "security.kerberos.login.use-ticket-cache" -> "true"
        //        "jobmanager.rpc.port" -> "6123"
        //        "security.kerberos.login.principal" -> "yarn/henghe-030@HENGHE.COM"
        //        "sun.security.krb5.debug" -> "true"
        //        "execution.savepoint.ignore-unclaimed-state" -> {Boolean@3562} false
        //        "execution.attached" -> {Boolean@3564} true
        //        "execution.shutdown-on-attached-exit" -> {Boolean@3562} false
        //        "pipeline.jars" -> {ArrayList@3567}  size = 1
        //        "parallelism.default" -> {Integer@3569} 4
        //        "taskmanager.numberOfTaskSlots" -> "1"
        //        "pipeline.classpaths" -> {ArrayList@3573}  size = 0
        //        "security.kerberos.login.keytab" -> "/opt/keytab/yarn.keytab"
        //        "$internal.deployment.config-dir" -> "/opt/tools/flink-1.12.0/conf"

        FlinkPipelineTranslator pipelineTranslator = getPipelineTranslator(pipeline);


        // StreamGraphTranslator#translateToJobGraph
        return pipelineTranslator.translateToJobGraph(
                pipeline, optimizerConfiguration, defaultParallelism);
    }

    /**
     * Transmogrifies the given {@link Pipeline} under the userClassloader to a {@link JobGraph}.
     */
    public static JobGraph getJobGraphUnderUserClassLoader(
            final ClassLoader userClassloader,
            final Pipeline pipeline,
            final Configuration configuration,
            final int defaultParallelism) {
        final ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();
        try {
            Thread.currentThread().setContextClassLoader(userClassloader);
            return FlinkPipelineTranslationUtil.getJobGraph(
                    pipeline, configuration, defaultParallelism);
        } finally {
            Thread.currentThread().setContextClassLoader(contextClassLoader);
        }
    }

    /** Extracts the execution plan (as JSON) from the given {@link Pipeline}. */
    public static String translateToJSONExecutionPlan(Pipeline pipeline) {
        FlinkPipelineTranslator pipelineTranslator = getPipelineTranslator(pipeline);
        return pipelineTranslator.translateToJSONExecutionPlan(pipeline);
    }

    private static FlinkPipelineTranslator getPipelineTranslator(Pipeline pipeline) {
        PlanTranslator planTranslator = new PlanTranslator();

        if (planTranslator.canTranslate(pipeline)) {
            return planTranslator;
        }

        StreamGraphTranslator streamGraphTranslator = new StreamGraphTranslator();

        if (streamGraphTranslator.canTranslate(pipeline)) {
            return streamGraphTranslator;
        }

        throw new RuntimeException(
                "Translator "
                        + streamGraphTranslator
                        + " cannot translate "
                        + "the given pipeline "
                        + pipeline
                        + ".");
    }
}
